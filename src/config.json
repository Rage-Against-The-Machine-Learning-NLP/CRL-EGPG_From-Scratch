{
  "model_name": "Seq2Seq",
  "glove_file": "./glove/glove.6B.300d.txt",
  "dataset_dir": "../data/quora/processed/",
  "vocab_file": "word_to_index.pkl",
  "embedding_dim": 300,
  "vocabulary_dim": 23922,
  "encoder": {
    "hidden_dim": 512,
    "input_dim": 300,
    "num_layers": 1,
    "bidirectional": 1,
    "final_out_dim": 1024,
    "drop_out": 0.2
  },
  "decoder": {
    "hidden_dim": 512,
    "input_dim": 1324,
    "num_layers": 1,
    "drop_out": 0.2
  },
  "style_attn": {
    "style_in": 768,
    "style_out": 300
  },
  "training": {
    "save_freq": 15,
    "batch_size": 128,
    "num_epochs": 45,
    "learning_rate": 0.0001,
    "max_sent_len": 15,
    "seq2seq_model_type": "gru",
    "style_extractor_model_type": "bert",
    "model_save_dir": "../models/",
    "loss_file": "../results/loss.pkl",
    "perplexity_file": "../results/ppl.pkl"
  }
}