{
  "model_name": "Seq2Seq",
  "embedding_dim": 300,
  "vocabulary_dim": 23923,
  "glove_file": "../glove/glove.6B.300d.txt",
  "dataset_dir": "../data/quora/processed/",
  "vocab_file": "word_to_index.pkl",
  "model_save_dir": "../models/",
  "results_dir": "../results/",
  "encoder": {
    "hidden_dim": 512,
    "input_dim": 300,
    "num_layers": 1,
    "bidirectional": 1,
    "final_out_dim": 1024,
    "drop_out": 0.2
  },
  "decoder": {
    "hidden_dim": 512,
    "input_dim": 1324,
    "num_layers": 1,
    "drop_out": 0.2
  },
  "style_attn": {
    "style_in": 768,
    "style_out": 300
  },
  "training": {
    "batch_size": 128,
    "num_epochs": 45,
    "learning_rate": 0.0001,
    "max_sent_len": 15,
    "seq2seq_model_type": "gru",
    "style_extractor_model_type": "bert",
    "loss_file": "loss.pkl",
    "perplexity_file": "ppl.pkl"
  }
}